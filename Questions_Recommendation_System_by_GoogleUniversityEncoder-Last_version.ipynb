{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load google universal sentence encoder model ----------------------> this have to be ruuning all the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1- load google universal sentence encoder : this function have to be running before the above cell!\n",
    "'''\n",
    "def embed_useT(module):\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.placeholder(tf.string)\n",
    "        embed = hub.Module(module)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.train.MonitoredSession()\n",
    "    return lambda x: session.run(embeddings, {sentences: x})\n",
    "\n",
    "embed_fn = embed_useT('G:\\sentence_wise_email\\module\\module_useT') #loading the model #------> rasmy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime \n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining the Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_csv_file = 'questions_recommendation_system_pl.csv'\n",
    "sw_csv_file = 'questions_recommendation_system_sw.csv'\n",
    "ai_csv_file = 'questions_recommendation_system_ai.csv'\n",
    "\n",
    "pl_embeddings_file_name = 'pl_embeddings_GoogleUSE'\n",
    "sw_embeddings_file_name = 'sw_embeddings_GoogleUSE'\n",
    "ai_embeddings_file_name = 'ai_embeddings_GoogleUSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2- load needed variables that must be loaded all the time : this variables have to be exist all the time\n",
    "'''\n",
    "def load_needed_variables(csv_dir,embeddings_file_name):\n",
    "    df = load_data(csv_dir) \n",
    "\n",
    "    #load embedding\n",
    "    concatenated_vector = load_embedding(embeddings_file_name)\n",
    "    \n",
    "    #get embedded vectors\n",
    "    embedded_vectors = undo_concatenate(concatenated_vector)\n",
    "\n",
    "    \n",
    "    return df, embedded_vectors\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "'''\n",
    "3- get the topic name from the data frame\n",
    "'''\n",
    "def get_Topic(df,id):  \n",
    "    return df['Topic_name'][id] # Just reads the results out of the dictionary.\n",
    "\n",
    "'''\n",
    "4- get the question from the data frame\n",
    "'''\n",
    "def get_question(df,id):  \n",
    "    return df['Question'][id] # Just reads the results out of the dictionary.\n",
    "\n",
    "'''\n",
    "5- get the distractor from the data frame\n",
    "'''\n",
    "def get_Distractor(df,id):  \n",
    "    return df['List_of_distractors'][id] # Just reads the results out of the dictionary.\n",
    "\n",
    "'''\n",
    "6- get the answer from the data frame\n",
    "'''\n",
    "def get_answer(df,id):  \n",
    "    return df['Answer'][id] # Just reads the results out of the dictionary.\n",
    "\n",
    "'''\n",
    "7- get the distractor without answer from the data frame\n",
    "'''\n",
    "def get_Distractor_without_answer(df,id):  \n",
    "    return df['dis_without_answer'][id] # Just reads the results out of the dictionary.\n",
    "\n",
    "'''\n",
    "8- load the data\n",
    "'''\n",
    "def load_data(csv_dir):\n",
    "    #upload enhanced_data.csv\n",
    "    df = pd.read_csv(csv_dir)\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    for i in df['List_of_distractors']:\n",
    "        df['List_of_distractors'][counter]=ast.literal_eval(i)\n",
    "        counter=counter+1\n",
    "    \n",
    "    counter=0\n",
    "    for i in df['dis_without_answer']:\n",
    "        df['dis_without_answer'][counter]=ast.literal_eval(i)\n",
    "        counter=counter+1\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "'''\n",
    "9- embedding our question topic names.\n",
    "'''\n",
    "def embedding_all_question_topics_name(all_docs):       \n",
    "    embedding_time = 0\n",
    "    embedding_start_time = datetime.now() \n",
    "    \n",
    "    encoding_matrix = embed_fn(all_docs)\n",
    "    \n",
    "    print(\"all Question Topics are embedded.\")\n",
    "    embedding_time =format(datetime.now() - embedding_start_time)\n",
    "\n",
    "    print('embedding_time (hh:mm:ss.ms) {}'.format(datetime.now() - embedding_start_time))\n",
    "    print(\"\")\n",
    "    return encoding_matrix\n",
    "\n",
    "'''\n",
    "10- concatenate vectors\n",
    "'''\n",
    "def concatenate(encoder_vectors_array):\n",
    "    concatenate_time = 0\n",
    "    concatenate_start_time = datetime.now() \n",
    "    \n",
    "    concatenated_vector= list()\n",
    "    for each_vector in encoder_vectors_array:\n",
    "        for each_value in each_vector:\n",
    "            concatenated_vector.append(each_value)\n",
    "        concatenated_vector.append(\"end_vec\") #delimeter\n",
    "        \n",
    "    concatenate_time = format(datetime.now() - concatenate_start_time)\n",
    "    print('concatenation_time (hh:mm:ss.ms) {}'.format(datetime.now() - concatenate_start_time))\n",
    "    print(\"\")\n",
    "    return concatenated_vector\n",
    "\n",
    "\n",
    "'''\n",
    "11- save embeddings.\n",
    "'''\n",
    "def save_embedding(concatenated_vector , embeddings_file_name):\n",
    "    \n",
    "    save_embedding_time = 0\n",
    "    save_embedding_start_time = datetime.now() \n",
    "    \n",
    "    # save embeddings\n",
    "    pickle_out = open(embeddings_file_name + \".pickle\",\"wb\")\n",
    "    pickle.dump(concatenated_vector, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    save_embedding_time =format(datetime.now() - save_embedding_start_time)\n",
    "    print('save_embedding_time (hh:mm:ss.ms) {}'.format(datetime.now() - save_embedding_start_time))\n",
    "    print(\"\")\n",
    "    \n",
    "    return 1\n",
    "\n",
    "\n",
    "'''\n",
    "12- to embed all course question topics and save them.\n",
    "'''\n",
    "\n",
    "#create_course_questions_topics_embeddings_and_save_embeddings\n",
    "def creat_and_save_course_embeddings(csv_dir , embeddings_file_name):\n",
    "    df = load_data(csv_dir)\n",
    "\n",
    "    #all documents we have.\n",
    "    all_docs=[]\n",
    "    for i in df['Topic_name']:\n",
    "        all_docs.append(i)\n",
    "    print(\"all docs are ready to be embedded...\")\n",
    "    \n",
    "    \n",
    "    #embedding questions topic\n",
    "    encoding_matrix = embedding_all_question_topics_name(all_docs)\n",
    "    print(\"all docs are embedded into vectors...\")\n",
    "    \n",
    "    \n",
    "    #concatenate vectors to store it\n",
    "    concatenated_vector = concatenate(encoding_matrix)\n",
    "    print(\"all vectors are concatenated...\")\n",
    "\n",
    "    return_result = save_embedding(concatenated_vector , embeddings_file_name)\n",
    "    \n",
    "    if (return_result==1):\n",
    "        print(\"done! , model is saved.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"ops! , model is not saved.\")\n",
    "    \n",
    "    return 1\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "'''\n",
    "13- load concatenated embedded vectors.\n",
    "'''\n",
    "def load_embedding(embeddings_file_name):   \n",
    "    load_embedding_time = 0\n",
    "    load_embedding_start_time = datetime.now() \n",
    "    \n",
    "    # load embeddings\n",
    "    pickle_in = open(embeddings_file_name + \".pickle\", \"rb\")\n",
    "    concatenated_vector = pickle.load(pickle_in)\n",
    "    \n",
    "    load_embedding_time = format(datetime.now() - load_embedding_start_time)\n",
    "    print('load_embedding_time (hh:mm:ss.ms) {}'.format(datetime.now() - load_embedding_start_time))\n",
    "    print(\"\")\n",
    "    \n",
    "    return concatenated_vector\n",
    "\n",
    "\n",
    "'''\n",
    "14- undo concatenating vectors.\n",
    "'''\n",
    "def undo_concatenate(concatenated_vector):\n",
    "    undo_concatenate_time = 0\n",
    "    undo_concatenate_start_time = datetime.now() \n",
    "    \n",
    "    embeded_vectors=[]\n",
    "    each_vec=[]\n",
    "    for each_value in concatenated_vector:\n",
    "\n",
    "        if(each_value!='end_vec'): #delimeter\n",
    "            each_vec.append(each_value)\n",
    "        else:\n",
    "            embeded_vectors.append(each_vec)\n",
    "            each_vec=[]\n",
    "            \n",
    "    undo_concatenate_time = format(datetime.now() - undo_concatenate_start_time)\n",
    "    print('undo_concatenation_time (hh:mm:ss.ms) {}'.format(datetime.now() - undo_concatenate_start_time))\n",
    "    print(\"\")\n",
    "    \n",
    "    return embeded_vectors\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "'''\n",
    "15- embedding user input.\n",
    "'''\n",
    "def embedding_user_input(user_input):\n",
    "    embedding_user_time = 0\n",
    "    embedding_user_start_time = datetime.now() \n",
    "    \n",
    "    encoding_user_vector = embed_fn([user_input])  #--------> rasmy\n",
    "    print(\"User Input is embedded.\")\n",
    "    \n",
    "    embedding_user_time =format(datetime.now() - embedding_user_start_time)\n",
    "    print('embedding_user_time (hh:mm:ss.ms) {}'.format(datetime.now() - embedding_user_start_time))\n",
    "    print(\"\")\n",
    "    \n",
    "    return encoding_user_vector\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "'''\n",
    "16- get cosine similarity\n",
    "'''\n",
    "def get_cosine_sim(first_element, second_element):\n",
    "    sim_matrix=cosine_similarity(first_element, second_element)\n",
    "    return sim_matrix\n",
    "\n",
    "'''\n",
    "17- sort cosine similarity values to get the most high 100 scores\n",
    "'''\n",
    "def sort_cosine_similarity(cosine_similarities):\n",
    "    related_docs_indices = cosine_similarities[0][:-2].argsort()[:-100:-1]\n",
    "    return related_docs_indices\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "'''\n",
    "18- returns alist of all the recomented questions\n",
    "'''\n",
    "\n",
    "def Recommend_Question(cosine_similarities,related_docs_indices,df):\n",
    "\n",
    "    similarity_time = 0\n",
    "    similarity_start_time = datetime.now() \n",
    "    \n",
    "    list_result=list()\n",
    "    recommended_questions_list=list()\n",
    "    all_questions=list()\n",
    "    i=0\n",
    "    for rec in cosine_similarities[-1][related_docs_indices]: \n",
    "\n",
    "        if (float(rec) > 0.7): #threshold to return the most similar questions\n",
    "            whole_question_list=list()\n",
    "            answer = get_answer(df,related_docs_indices[i])\n",
    "            dis_without_ans = get_Distractor_without_answer(df,related_docs_indices[i])\n",
    "            Question=get_question(df,related_docs_indices[i])\n",
    "\n",
    "            whole_question_list.append(answer)\n",
    "            for each_element in dis_without_ans:\n",
    "                whole_question_list.append(each_element)\n",
    "            whole_question_list.append(Question)\n",
    "            \n",
    "            all_questions.append(whole_question_list)    \n",
    "        i=i+1\n",
    "    \n",
    "    similarity_time =format(datetime.now() - similarity_start_time)\n",
    "    print('similarity_time (hh:mm:ss.ms) {}'.format(datetime.now() - similarity_start_time))\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "19- get the similarity between the embedded user input and the embedded question topics \n",
    "names and recommend the most similar questions and return them in a dictionary.\n",
    "'''\n",
    "def recommend_most_similar_questions(user_input, csv_dir , embeddings_file_name):\n",
    "    #load needed variables\n",
    "    df, encoding_matrix = load_needed_variables(csv_dir , embeddings_file_name)\n",
    "    \n",
    "    #embedding user input\n",
    "    encoding_user_vector = embedding_user_input(user_input)\n",
    "\n",
    "    #get the cosine similarity between user input and all question topics in the course\n",
    "    sim_matrix = get_cosine_sim(encoding_user_vector, encoding_matrix)\n",
    "\n",
    "    #sort cosine similarity values to get the most high 100 scores\n",
    "    related_docs_indices = sort_cosine_similarity(sim_matrix)\n",
    "    \n",
    "    #recommend Questions based on the similarity between user input and question topics names\n",
    "    all_questions = Recommend_Question(sim_matrix,related_docs_indices,df)\n",
    "\n",
    "    #create dictionary \n",
    "    dic = {}\n",
    "    c=0\n",
    "    for each_list in all_questions:\n",
    "        dic[c] = each_list\n",
    "        c=c+1\n",
    "        \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding and save embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_result_pl = creat_and_save_course_embeddings(pl_csv_file , pl_embeddings_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_result_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_result_sw = creat_and_save_course_embeddings(sw_csv_file , sw_embeddings_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_result_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_result_ai = creat_and_save_course_embeddings(ai_csv_file , ai_embeddings_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_result_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=\"Recursion (adjective: recursive) occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references can occur. Recursion is the process a procedure goes through when one of the steps of the procedure involves invoking the procedure itself. A procedure that goes through recursion is said to be 'recursive'.[3] To understand recursion, one must recognize the distinction between a procedure and the running of a procedure. A procedure is a set of steps based on a set of rules, while the running of a procedure involves actually following the rules and performing the steps. Recursion is related to, but not the same as, a reference within the specification of a procedure to the execution of some other procedure. When a procedure is defined as such, this immediately creates the possibility of an endless loop; recursion can only be properly used in a definition if the step in question is skipped in certain cases so that the procedure can complete. But even if it is properly defined, a recursive procedure is not easy for humans to perform, as it requires distinguishing the new from the old, partially executed invocation of the procedure; this requires some administration as to how far various simultaneous instances of the procedures have progressed. For this reason, recursive definitions are very rare in everyday situations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_embedding_time (hh:mm:ss.ms) 0:00:05.401818\n",
      "\n",
      "undo_concatenation_time (hh:mm:ss.ms) 0:00:04.180536\n",
      "\n",
      "User Input is embedded.\n",
      "embedding_user_time (hh:mm:ss.ms) 0:00:03.822091\n",
      "\n",
      "similarity_time (hh:mm:ss.ms) 0:00:00.014959\n"
     ]
    }
   ],
   "source": [
    "dic=recommend_most_similar_questions(user_input, pl_csv_file , pl_embeddings_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['Run time error',\n",
       "  'Compile time error',\n",
       "  'Logical error',\n",
       "  'No error',\n",
       "  'In the absence of a exit condition in a recursive function, the following error is given __________'],\n",
       " 1: ['24',\n",
       "  '4',\n",
       "  '12',\n",
       "  '10',\n",
       "  'What will be the output of the following C code?\\n#include<stdio.h>\\nmain()\\n{\\nint n;\\nn=f1(4);\\nprintf(\"%d\",n);\\n}\\nf1(int x)\\n{\\nint b;\\nif(x==1)\\nreturn 1;\\nelse\\nb=x*f1(x-1);\\nreturn b;\\n}'],\n",
       " 2: ['Last in first out',\n",
       "  'First in first out',\n",
       "  'First in last out',\n",
       "  'Last in last out',\n",
       "  'The principle of stack is __________'],\n",
       " 3: ['++++2',\n",
       "  '+++++2',\n",
       "  '+++++',\n",
       "  '2',\n",
       "  'What will be the output of the following C code?\\n#include<stdio.h>\\nmain()\\n{\\nint n,i;\\nn=f(6);\\nprintf(\"%d\",n);\\n}\\nf(int x)\\n{\\nif(x==2)\\nreturn 2;\\nelse\\n{\\nprintf(\"+\");\\nf(x-1);\\n}\\n}'],\n",
       " 4: ['Infinite number of times',\n",
       "  '9 times',\n",
       "  '10 times',\n",
       "  '0 times',\n",
       "  'How many times is ‘a’ printed when the following C code is executed?\\n#include<stdio.h>\\nmain()\\n{\\nint a;\\na=f1(10);\\nprintf(\"%d\",a);\\n}\\nf1(int b)\\n{\\nif(b==0)\\nreturn 0;\\nelse\\n{\\nprintf(\"a\");\\nf1(b--);\\n}\\n}'],\n",
       " 5: ['30',\n",
       "  '10',\n",
       "  '80',\n",
       "  'Error',\n",
       "  'What will be the output of the following C code?\\n#include<stdio.h>\\nmain()\\n{\\nint n=10;\\nint f(int n);\\nprintf(\"%d\",f(n));\\n}\\nint f(int n)\\n{\\nif(n>0)\\nreturn(n+f(n-2));\\n}'],\n",
       " 6: ['Hello infinite number of times',\n",
       "  'Hello is printed once',\n",
       "  'Hello is not printed at all',\n",
       "  '0 is returned',\n",
       "  'What will be the output of the following C code?\\n#include<stdio.h>\\nint main()\\n{\\nprintf(\"Hello\");\\nmain();\\nreturn 0;\\n}'],\n",
       " 7: ['dlrowolleh',\n",
       "  'helloworld',\n",
       "  'infinite loop',\n",
       "  'llehdlrowo',\n",
       "  'What will be the output of the following C code if the input given to the code shown below is “helloworld”?\\n#include<stdio.h>\\n#define NL \\'\\\\n\\'\\nmain()\\n{\\nvoid f(void);\\nprintf(\"enter the word\\\\n\");\\nf();\\n}\\nvoid f(void)\\n{\\nchar c;\\nif((c=getchar())!=NL)\\n{\\nf();\\nprintf(\"%c\",c);\\n}\\nreturn;\\n}'],\n",
       " 8: ['False', 'True', 'Iteration requires more system memory than recursion.'],\n",
       " 9: ['Stack',\n",
       "  'Array',\n",
       "  'Linked list',\n",
       "  'Binary tree',\n",
       "  'The data structure used to implement recursive function calls _____________']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=\"A neural networks is a network or circuit of neurons, or in a modern sense, an artificial neural network, composed of artificial neurons or nodes.[1] Thus a neural network is either a biological neural network, made up of real biological neurons, or an artificial neural network, for artificial intelligence . The connections of the biological neuron are modeled as weights. A positive weight reflects an excitatory connection, while negative values mean inhibitory connections. All inputs are modified by a weight and summed. This activity is referred to as a linear combination. Finally, an activation function controls the amplitude of the output. For example, an acceptable range of output is usually between 0 and 1, or it could be −1 and 1. These artificial networks may be used for predictive modeling, adaptive control and applications where they can be trained via a dataset. Self-learning resulting from experience can occur within networks, which can derive conclusions from a complex and seemingly unrelated set of information.[2]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_embedding_time (hh:mm:ss.ms) 0:00:00.281626\n",
      "\n",
      "undo_concatenation_time (hh:mm:ss.ms) 0:00:01.690482\n",
      "\n",
      "User Input is embedded.\n",
      "embedding_user_time (hh:mm:ss.ms) 0:00:00.137601\n",
      "\n",
      "similarity_time (hh:mm:ss.ms) 0:00:00.001994\n"
     ]
    }
   ],
   "source": [
    "dic=recommend_most_similar_questions(user_input, ai_csv_file , ai_embeddings_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['a single layer feed-forward neural network with pre-processing',\n",
       "  'an auto-associative neural network',\n",
       "  'a double layer auto-associative neural network',\n",
       "  'a neural network that contains feedback',\n",
       "  'What is perceptron?'],\n",
       " 1: ['True – perceptrons can do this but are unable to learn to do it – they have to be explicitly hand-coded',\n",
       "  'True – this works always, and these multiple perceptrons learn to classify even complex problems',\n",
       "  'False – perceptrons are mathematically incapable of solving linearly inseparable functions, no matter what you do',\n",
       "  'False – just having a single perceptron is enough',\n",
       "  'Having multiple perceptrons can actually solve the XOR problem satisfactorily: this is because each perceptron can partition off a linear part of the space itself, and they can then combine their results.'],\n",
       " 2: ['Because they are the only class of problem that Perceptron can solve successfully',\n",
       "  'Because they are the only class of problem that network can solve successfully',\n",
       "  'Because they are the only mathematical functions that are continue',\n",
       "  'Because they are the only mathematical functions you can draw',\n",
       "  'Why are linearly separable problems of interest of neural network researchers?'],\n",
       " 3: ['000 or 010 or 110 or 100',\n",
       "  '000 or 110 or 011 or 101',\n",
       "  '010 or 100 or 110 or 101',\n",
       "  '100 or 111 or 101 or 001',\n",
       "  'A 3-input neuron is trained to output a zero when the input is 110 and a one when the input is 111. After generalization, the output will be zero when and only when the input is?'],\n",
       " 4: ['It is the transmission of error back through the network to allow weights to be adjusted so that the network can learn',\n",
       "  'It is another name given to the curvy function in the perceptron',\n",
       "  'It is the transmission of error back through the network to adjust the inputs',\n",
       "  'None of the mentioned',\n",
       "  'What is back propagation?'],\n",
       " 5: ['Because it is the simplest linearly inseparable problem that exists.',\n",
       "  'Because it can be expressed in a way that allows you to use a neural network',\n",
       "  'Because it is complex binary operation that cannot be solved using neural networks',\n",
       "  'Because it can be solved by a single layer perceptron',\n",
       "  'Why is the XOR problem exceptionally interesting to neural network researchers?'],\n",
       " 6: ['It can explain result',\n",
       "  'It can survive the failure of some nodes',\n",
       "  'It has inherent parallelism',\n",
       "  'It can handle noise',\n",
       "  'Which of the following is not the promise of artificial neural network?'],\n",
       " 7: ['Linear Functions',\n",
       "  'Nonlinear Functions',\n",
       "  'Discrete Functions',\n",
       "  'Exponential Functions',\n",
       "  'Neural Networks are complex ______________ with many parameters.'],\n",
       " 8: ['True',\n",
       "  'False',\n",
       "  'Sometimes – it can also output intermediate values as well',\n",
       "  'Can’t say',\n",
       "  'A perceptron adds up all the weighted inputs it receives, and if it exceeds a certain value, it outputs a 1, otherwise it just outputs a 0.'],\n",
       " 9: ['Heaviside function',\n",
       "  'Step function',\n",
       "  'Logistic function',\n",
       "  'Perceptron function',\n",
       "  'What is the name of the function in the following statement “A perceptron adds up all the weighted inputs it receives, and if it exceeds a certain value, it outputs a 1, otherwise it just outputs a 0”?'],\n",
       " 10: ['Recurrent neural network',\n",
       "  'Self organizing maps',\n",
       "  'Perceptrons',\n",
       "  'Multi layered perceptron',\n",
       "  'The network that involves backward links from output to the input and hidden layers is called _________'],\n",
       " 11: ['All of the mentioned',\n",
       "  'Sales forecasting',\n",
       "  'Data validation',\n",
       "  'Risk management',\n",
       "  'Which of the following is an application of NN (Neural Network)?'],\n",
       " 12: ['It is powerful and easy neural network',\n",
       "  'A software used to analyze neurons',\n",
       "  'Designed to aid experts in real world',\n",
       "  'It is software used by Neurosurgeon',\n",
       "  'What is Neuro software?'],\n",
       " 13: ['All of the mentioned',\n",
       "  'It has set of nodes and connections',\n",
       "  'Each node computes it’s weighted input',\n",
       "  'Node could be in excited state or non-excited state',\n",
       "  'Which is true for neural networks?'],\n",
       " 14: ['(ii) and (iii) are true',\n",
       "  '(ii) is true',\n",
       "  'All of the mentioned',\n",
       "  'None of the mentioned',\n",
       "  'Which of the following is true?\\nSingle layer associative neural networks do not have the ability to:\\n(i) perform pattern recognition\\n(ii) find the parity of a picture\\n(iii)determine whether two or more shapes in a picture are connected or not'],\n",
       " 15: ['All of the mentioned',\n",
       "  '(i) and (ii) are true',\n",
       "  '(i) and (iii) are true',\n",
       "  'Only (i)',\n",
       "  'What are the advantages of neural networks over conventional computers?\\n(i) They have the ability to learn by example\\n(ii) They are more fault tolerant\\n(iii)They are more suited for real time operation due to their high ‘computational’ rates'],\n",
       " 16: ['(i) and (ii) are true',\n",
       "  'All of the mentioned',\n",
       "  '(ii) is true',\n",
       "  'None of the mentioned',\n",
       "  'Which of the following is true for neural networks?\\n(i) The training time depends on the size of the network.\\n(ii) Neural networks can be simulated on a conventional computer.\\n(iii) Artificial neurons are identical in operation to biological ones.'],\n",
       " 17: ['All of the mentioned are true',\n",
       "  '(ii) and (iii) are true',\n",
       "  '(i), (ii) and (iii) are true',\n",
       "  'None of the mentioned',\n",
       "  'Which of the following is true?\\n(i) On average, neural networks have higher computational rates than conventional computers.\\n(ii) Neural networks learn by example.\\n(iii) Neural networks mimic the way the human brain works.'],\n",
       " 18: ['238',\n",
       "  '76',\n",
       "  '119',\n",
       "  '123',\n",
       "  'A 4-input neuron has weights 1, 2, 3 and 4. The transfer function is linear with the constant of proportionality being equal to 2. The inputs are 4, 10, 5 and 20 respectively. What will be the output?'],\n",
       " 19: ['a neural network that contains feedback',\n",
       "  'a neural network that contains no loops',\n",
       "  'a neural network that has only one loop',\n",
       "  'a single layer feed-forward neural network with pre-processing',\n",
       "  'What is an auto-associative network?']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=\"In software engineering, a software design pattern is a general, reusable solution to a commonly occurring problem within a given context in software design. It is not a finished design that can be transformed directly into source or machine code. Rather, it is a description or template for how to solve a problem that can be used in many different situations. Design patterns are formalized best practices that the programmer can use to solve common problems when designing an application or system. Object-oriented design patterns typically show relationships and interactions between classes or objects, without specifying the final application classes or objects that are involved. Patterns that imply mutable state may be unsuited for functional programming languages, some patterns can be rendered unnecessary in languages that have built-in support for solving the problem they are trying to solve, and object-oriented patterns are not necessarily suitable for non-object-oriented languages. Design patterns may be viewed as a structured approach to computer programming intermediate between the levels of a programming paradigm and a concrete algorithm.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "G:\\AnacondaSetup\\envs\\New_Env\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_embedding_time (hh:mm:ss.ms) 0:00:00.379340\n",
      "\n",
      "undo_concatenation_time (hh:mm:ss.ms) 0:00:03.072818\n",
      "\n",
      "User Input is embedded.\n",
      "embedding_user_time (hh:mm:ss.ms) 0:00:00.118652\n",
      "\n",
      "similarity_time (hh:mm:ss.ms) 0:00:00.000998\n"
     ]
    }
   ],
   "source": [
    "dic=recommend_most_similar_questions(user_input, sw_csv_file , sw_embeddings_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['Player-Role Pattern',\n",
       "  'Abstraction-Occurrence Pattern',\n",
       "  'General Hierarchy Pattern',\n",
       "  'Singleton Pattern',\n",
       "  'You want to avoid multiple inheritance. Which design pattern would you choose?'],\n",
       " 1: ['all of the mentioned',\n",
       "  'encapsulating the knowledge of which document subclass to is to be created and',\n",
       "  'moving this knowledge out of the framework',\n",
       "  'instantiating the application specific documents without knowing their class',\n",
       "  'In factory method pattern, the framework must instantiate classes but it only knows about the abstract classes, which it cannot initiate. How would one solve this problem?'],\n",
       " 2: ['False',\n",
       "  'True',\n",
       "  'Design patterns does not follow the concept of software reuse.'],\n",
       " 3: ['All of the mentioned',\n",
       "  'Component-based software engineering',\n",
       "  'Reusability in general',\n",
       "  'None of the mentioned',\n",
       "  'The use of design patterns for the development of object-oriented software has important implications for'],\n",
       " 4: ['All of the mentioned',\n",
       "  'Behavioral',\n",
       "  'Structural',\n",
       "  'Abstract Factory',\n",
       "  'Which of the following is a design pattern?'],\n",
       " 5: ['Delegation pattern',\n",
       "  'Adapter Pattern',\n",
       "  'Singleton Pattern',\n",
       "  'Immutable Pattern',\n",
       "  'You want to minimize development cost by reusing methods? Which design pattern would you choose?'],\n",
       " 6: ['All of the mentioned',\n",
       "  'Inheritance',\n",
       "  'Composition',\n",
       "  'None of the mentioned',\n",
       "  'Which mechanism is applied to use a design pattern in an OO system?'],\n",
       " 7: ['patterns',\n",
       "  'documents',\n",
       "  'structures',\n",
       "  'methods',\n",
       "  'The recurring aspects of designs are called design'],\n",
       " 8: ['True',\n",
       "  'False',\n",
       "  'Design pattern is a solution to a problem that occurs repeatedly in a variety of contexts.'],\n",
       " 9: ['Singleton',\n",
       "  'Factory Method',\n",
       "  'Observer',\n",
       "  'None of the mentioned',\n",
       "  'Which pattern prevents one from creating more than one instance of a variable?'],\n",
       " 10: ['True',\n",
       "  'False',\n",
       "  'Facade pattern promotes weak coupling between subsystem and its clients.'],\n",
       " 11: ['Observer pattern',\n",
       "  'Singleton pattern',\n",
       "  'Facade Pattern',\n",
       "  'Factory method pattern',\n",
       "  'Which design pattern defines one-to-many dependency among objects?'],\n",
       " 12: ['False', 'True', 'Facade pattern couples a subsystem from its clients.']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
